
> # Hyperparameter flags ---------------------------------------------------
> 
> FLAGS <- flags(
+   flag_numeric("dropout1", 0.25),
+   flag_integer .... [TRUNCATED] 

> ## initialisation du rÃ©seau
> lambda.hom <- sum(learnNN$ClaimNb)/sum(learnNN$Exposure)

> # Define Model --------------------------------------------------------------
> 
> features.0 <- layer_input(shape=c(ncol(XlearnNN)))         # defi .... [TRUNCATED] 

> net <- features.0 %>%
+   #on ajoute kernel initialize direct dans le dense layer
+   layer_dense(units = FLAGS$hidden1,activation="relu",kernel_ini .... [TRUNCATED] 

> volumes.0 <- layer_input(shape=c(1))                     # define network for offset

> merged <- list(net, volumes.0) %>%                          # combine the two networks
+   layer_add(name='Add') %>% 
+   layer_dense(units=1, activ .... [TRUNCATED] 

> model_shallow <- keras_model(inputs=list(features.0, volumes.0), outputs=merged)

> model_shallow %>% compile(loss = Poisson.Deviance, optimizer = "nadam")

> # Training & Evaluation ----------------------------------------------------
> 
> history <- model_shallow %>% fit(list(XlearnNN, WlearnNN), 
+      .... [TRUNCATED] 

> data_fit <- as.data.frame(history)

> ggplot(data_fit[which(!is.na(data_fit$value)),],aes(x=epoch,y=value,col=data))+
+   geom_point()

> score_test <- model_shallow %>% evaluate(
+   list(XtestNN,WtestNN), YtestNN,
+   verbose = 0
+ )

> score_val <- model_shallow %>% evaluate(
+   list(XvalNN,WvalNN),YvalNN,
+   verbose = 0
+ )
